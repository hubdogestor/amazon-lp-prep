// Case 3 - broad_responsibility
const case_3 = {
  id: "sicredi-responsible-ai-policy",
  title: "Impacto Amplo das Decisões: Política de IA Responsável com Responsabilidade Social, Equidade e Transparência",
  title_pt: "Impacto Amplo das Decisões: Política de IA Responsável com Responsabilidade Social, Equidade e Transparência",
  title_en: "Broader Impact of Decisions: Responsible AI Policy with Social Responsibility, Equity and Transparency",
  company: "Sicredi",
  period: "01/2020-12/2020",
  isTopCase: false,
  isGoodCase: false,
  pt: {
    s: `"120 mil vidas financeiras. Modelo aprovado. Taxa de aprovação para autônomos: 23% menor. Viés confirmado antes do deploy." No Sicredi, ao introduzirmos o primeiro modelo de ML para pré-aprovação de crédito, o sucesso trouxe uma nova e complexa responsabilidade. A escala do negócio significava que as decisões do algoritmo impactariam a vida financeira de 120 mil+ cooperados. Antes de implementar, analisei impactos em 3 dimensões: (1) cooperados (120k pessoas, 28% autônomos historicamente sub-representados em crédito), (2) reguladores (BACEN com foco crescente em equidade algorítmica), (3) sociedade (risco de perpetuar vieses contra trabalhadores autônomos e minorias). Quando propus uma "Política de IA Responsável", enfrentei resistência imediata: o VP Comercial argumentou que "auditorias éticas atrasariam lançamentos" e que "concorrentes não fazem isso". Mas o impacto amplo de decisões erradas - multas, reputação, exclusão financeira de milhares - era uma responsabilidade que eu precisava endereçar, mesmo contra a resistência interna.`,
    t: `Meu papel individual: eu liderei end-to-end, defini escopo e decisões críticas, e atuei como owner único. Minha tarefa era considerar impacto amplo das decisões de IA: não apenas acurácia do modelo (métrica técnica), mas efeitos secundários em 120k+ cooperados, trabalhadores autônomos (28% da base, 33.600 pessoas), reguladores BACEN (fiscalização crescente), e futuras gerações (precedente de uso ético de dados). Eu precisava garantir que cada decisão do algoritmo fosse auditável, justa e transparente para toda a comunidade cooperativa. Minha tarefa foi liderar a criação da primeira 'Política de IA Responsável' do Sicredi, deixando as coisas melhores não apenas em tecnologia, mas em governança e responsabilidade social ampla.`,
    a: `Ações pessoais: priorizei mudanças, alinhei stakeholders, tomei decisões de trade-off e removi bloqueios. Iniciei o projeto apresentando pessoalmente à liderança os riscos reputacionais e regulatórios emergentes de IA enviesada, usando exemplos específicos de outras empresas. Argumentei veementemente que, para uma cooperativa baseada em princípios de equidade, a responsabilidade de garantir uma IA justa não era opcional, era central para a marca. Estudei intensivamente os frameworks de IA Responsável do Google e Microsoft porque eram os mais maduros do mercado, com casos de uso documentados em instituições financeiras, e incluíam ferramentas práticas de detecção de viés que eu poderia adaptar. Tomei a decisão de organizar um workshop com especialistas em ética de IA da UFRGS, enfrentando resistência inicial sobre custos. O insight chave foi o conceito de 'justiça contrafactual', que me ajudou a moldar testes de viés muito mais robustos que simples comparações demográficas. Redigi pessoalmente a política que instituía mecanismos concretos. Um deles foi o 'teste de viés' obrigatório que implementei para qualquer modelo que impactasse decisões de clientes. Quando os testes iniciais que supervisionei identificaram que o modelo estava penalizando injustamente trabalhadores autônomos (taxa de aprovação 23% menor vs. trabalhadores formais com mesmo perfil de risco), liderei pessoalmente a correção através de 'feature engineering'. Criei novas variáveis que representavam melhor a saúde financeira de um autônomo (regularidade de depósitos, diversidade de fontes de renda). Quando enfrentei pushback sobre complexidade adicional, justifiquei o ROI ético. A política que elaborei exigiu um processo de 'explicabilidade'. Liderei a criação de um sistema que traduzia a decisão do modelo em explicação simples, comunicada ao cliente, aumentando transparência e confiança.`,
    r: `A 'Política de IA Responsável' foi implementada e se tornou o padrão para todos os projetos de dados no Sicredi. Impacto amplo mensurável em 3 dimensões: (1) Cooperados - 18.000+ autônomos qualificados (15% de 120k base) ganharam acesso a crédito justo, taxa de aprovação aumentou 15% equiparando-se à de trabalhadores formais (de 23% abaixo para 2% abaixo da média), gerando R$ 47M+ em crédito liberado antes negado injustamente. (2) Reguladores - credibilidade com BACEN evitou fiscalização invasiva (3 concorrentes sofreram auditorias custando R$ 12M+ cada), fomos citados como caso de sucesso em circular sobre governança algorítmica. (3) Sociedade - framework replicado por 3 cooperativas (600k+ membros agregados), estabelecendo precedente de IA responsável no cooperativismo brasileiro, protegendo futuras gerações de exclusão financeira algorítmica.`,
    l: `Aprendi que considerar impacto amplo das decisões exige metodologia estruturada, não apenas boa intenção. Hoje uso 3 passos em todo projeto: (1) Mapear stakeholders secundários além do cliente direto - no caso IA foram autônomos (28% base), reguladores, sociedade, não só time de crédito; (2) Antecipar efeitos não intencionais com testes empíricos - 'justiça contrafactual' detectou viés que análise superficial perderia; (3) Criar governança para decisões em escala - Comitê de Ética com multidisciplinar (dados, negócio, jurídico, compliance, voz do cooperado) garante múltiplas perspectivas. Antes de qualquer projeto de tecnologia que lidero, pergunto 'Quem mais isso afeta além do usuário direto?' e documento respostas em matriz de impacto com mitigações. Responsabilidade sobre efeitos secundários cresce exponencialmente com escala - 120k decisões algorítmicas exigem governança proporcional.`
  },
  en: {
    s: `"120 thousand financial lives. Model approved. Approval rate for freelancers: 23% lower. Bias confirmed before deploy." At Sicredi, when introducing the first ML model for credit pre-approval, success brought a new and complex responsibility. Business scale meant the algorithm's decisions would impact 120k+ cooperative members' financial lives. Before implementing, I analyzed impacts across 3 dimensions: (1) members (120k people, 28% freelancers historically underrepresented in credit), (2) regulators (Central Bank with growing focus on algorithmic equity), (3) society (risk of perpetuating biases against freelance workers and minorities). When I proposed a "Responsible AI Policy," I faced immediate resistance: the Commercial VP argued that "ethical audits would delay launches" and that "competitors don't do this." But the broader impact of wrong decisions - fines, reputation, financial exclusion of thousands - was a responsibility I needed to address, even against internal resistance.`,
    t: `My individual role: I led end-to-end, set scope and critical decisions, and acted as the single-threaded owner. My task was to consider broader impact of AI decisions: not just model accuracy (technical metric), but secondary effects on 120k+ members, freelance workers (28% of base, 33,600 people), Central Bank regulators (increasing oversight), and future generations (precedent for ethical data use). I needed to ensure every algorithm decision was auditable, fair and transparent to the entire cooperative community. My task was to lead creation of Sicredi's first 'Responsible AI Policy', leaving things better not just in technology, but in governance and broad social responsibility.`,
    a: `Personal actions: I drove execution—prioritized changes, aligned stakeholders, made trade-offs, and unblocked teams. I personally presented to leadership the emerging reputational and regulatory risks of biased AI, using specific examples from other companies. I argued vehemently that, for a cooperative based on equity principles, the responsibility to ensure fair AI wasn't optional, it was central to the brand. I intensively studied Google and Microsoft's Responsible AI frameworks because they were the most mature in the market, with documented use cases in financial institutions, and included practical bias detection tools I could adapt. I made the decision to organize a workshop with AI ethics experts from UFRGS, facing initial resistance about costs. The key insight was the concept of 'counterfactual fairness', which helped me shape much more robust bias tests than simple demographic comparisons. I personally drafted the policy that instituted concrete mechanisms. One was mandatory 'bias testing' I implemented for any model impacting customer decisions. When initial tests I supervised identified the model was unfairly penalizing freelance workers (23% lower approval rate vs. formal workers with same risk profile), I personally led the correction through 'feature engineering'. I created new variables that better represented a freelancer's financial health (deposit regularity, income source diversity). When I faced pushback about additional complexity, I justified the ethical ROI. The policy I elaborated required an 'explainability' process. I led creation of a system that translated the model's decision into simple explanation, communicated to customers, increasing transparency and trust.`,
    r: `The 'Responsible AI Policy' was implemented and became the standard for all data projects at Sicredi. Measurable broader impact across 3 dimensions: (1) Members - 18,000+ qualified freelancers (15% of 120k base) gained access to fair credit, approval rate increased 15% equalizing with formal workers (from 23% below to 2% below average), generating R$ 47M+ in credit previously denied unfairly. (2) Regulators - credibility with Central Bank avoided invasive oversight (3 competitors suffered audits costing R$ 12M+ each), we were cited as success case in circular on algorithmic governance. (3) Society - framework replicated by 3 cooperatives (600k+ aggregate members), establishing precedent for responsible AI in Brazilian cooperativism, protecting future generations from algorithmic financial exclusion.`,
    l: `I learned that considering broader impact of decisions requires structured methodology, not just good intention. Today I use 3 steps in every project: (1) Map secondary stakeholders beyond direct customer - in AI case they were freelancers (28% base), regulators, society, not just credit team; (2) Anticipate unintended effects with empirical tests - 'counterfactual fairness' detected bias superficial analysis would miss; (3) Create governance for scale decisions - Ethics Committee with multidisciplinary (data, business, legal, compliance, member voice) ensures multiple perspectives. Before any technology project I lead, I ask 'Who else does this affect beyond direct user?' and document answers in impact matrix with mitigations. Responsibility for secondary effects grows exponentially with scale - 120k algorithmic decisions require proportional governance.`
  },
  fups: [
    {
        "q": "Qual foi seu maior erro ou falha nesse caso?",
        "a": "Meu maior erro foi subestimar a resistência inicial do VP Comercial. Acreditei que os dados sobre os riscos reputacionais e financeiros seriam suficientes para convencê-lo, mas a pressão por resultados de curto prazo era imensa. Tive que investir um tempo considerável em negociações e na construção de um business case sólido para conseguir o apoio necessário, o que atrasou o início do projeto em duas semanas.",
        "q_en": "What was your biggest mistake or failure in this case?",
        "a_en": "My biggest mistake was underestimating the initial resistance from the Commercial VP. I believed that the data on reputational and financial risks would be enough to convince him, but the pressure for short-term results was immense. I had to invest considerable time in negotiations and in building a solid business case to get the necessary support, which delayed the start of the project by two weeks."
    },
    {
        "q": "O que você faria diferente hoje?",
        "a": "Hoje, eu envolveria o VP Comercial desde o início, posicionando a IA Responsável não como um obstáculo, mas como uma vantagem competitiva e uma ferramenta de gestão de risco. Em vez de apresentar o problema, eu o convidaria a co-criar a solução, transformando-o em um patrocinador do projeto desde o primeiro dia. Isso teria acelerado a adesão e evitado o desgaste inicial.",
        "q_en": "What would you do differently today?",
        "a_en": "Today, I would involve the Commercial VP from the beginning, positioning Responsible AI not as an obstacle, but as a competitive advantage and a risk management tool. Instead of presenting the problem, I would invite him to co-create the solution, turning him into a sponsor of the project from day one. This would have accelerated buy-in and avoided the initial friction."
    },
    {
        "q": "Qual foi o obstáculo mais difícil de superar?",
        "a": "O obstáculo mais difícil foi a resistência da equipe de dados em relação à complexidade técnica da ‘explicabilidade’ dos modelos. Eles estavam focados na acurácia e viam a interpretabilidade como um luxo. Para superar isso, posicionei o desafio como uma oportunidade de inovação em engenharia e investi em ferramentas como SHAP, que facilitaram o processo e mostraram que era possível alcançar ambos os objetivos.",
        "q_en": "What was the most difficult obstacle to overcome?",
        "a_en": "The most difficult obstacle was the resistance from the data team regarding the technical complexity of the models' 'explainability.' They were focused on accuracy and saw interpretability as a luxury. To overcome this, I positioned the challenge as an opportunity for engineering innovation and invested in tools like SHAP, which facilitated the process and showed that it was possible to achieve both goals."
    },
    {
        "q": "Quais foram os principais riscos e como você os mitigou?",
        "a": "Os principais riscos eram a perpetuação de vieses contra trabalhadores autônomos, o que poderia levar a multas regulatórias e danos à reputação, e a exclusão financeira de milhares de cooperados. Mitiguei esses riscos com a criação da Política de IA Responsável, que incluía testes de viés obrigatórios, o Comitê de Ética para governança, e um sistema de ‘explicabilidade’ para garantir a transparência das decisões.",
        "q_en": "What were the main risks and how did you mitigate them?",
        "a_en": "The main risks were the perpetuation of biases against freelance workers, which could lead to regulatory fines and reputational damage, and the financial exclusion of thousands of cooperative members. I mitigated these risks by creating the Responsible AI Policy, which included mandatory bias testing, the Ethics Committee for governance, and an 'explainability' system to ensure the transparency of decisions."
    },
    {
        "q": "Que dados você usou para identificar o viés no modelo?",
        "a": "Usei uma técnica chamada ‘justiça contrafactual’, que aprendi no workshop com os especialistas da UFRGS. Em vez de apenas comparar dados demográficos, criei cenários hipotéticos para testar como o modelo se comportaria com perfis de risco idênticos, mas com diferentes tipos de vínculo empregatício. Foi essa análise que revelou a taxa de aprovação 23% menor para autônomos e nos permitiu corrigir o modelo.",
        "q_en": "What data did you use to identify the bias in the model?",
        "a_en": "I used a technique called 'counterfactual fairness,' which I learned in the workshop with the experts from UFRGS. Instead of just comparing demographic data, I created hypothetical scenarios to test how the model would behave with identical risk profiles, but with different types of employment relationships. It was this analysis that revealed the 23% lower approval rate for freelancers and allowed us to correct the model."
    },
    {
        "q": "Como você usou o aprendizado desse caso em outras frentes?",
        "a": "O framework de IA Responsável que criei foi replicado por outras três cooperativas, impactando mais de 600 mil membros. Além disso, a metodologia de mapear stakeholders secundários e antecipar efeitos não intencionais se tornou um padrão em todos os meus projetos. Antes de qualquer iniciativa de tecnologia que lidero, a pergunta ‘Quem mais isso afeta além do usuário direto?’ é o ponto de partida.",
        "q_en": "How did you use the learning from this case in other areas?",
        "a_en": "The Responsible AI framework I created was replicated by three other cooperatives, impacting more than 600,000 members. In addition, the methodology of mapping secondary stakeholders and anticipating unintended effects has become a standard in all my projects. Before any technology initiative I lead, the question 'Who else does this affect besides the direct user?' is the starting point."
    },
    {
        "q": "Como o Comitê de Ética em IA operava na prática?",
        "a": "O comitê se reunia mensalmente e funcionava como um ‘quality gate’. Nenhum modelo de IA entrava em produção sem a sua aprovação formal. Os critérios de aprovação eram baseados em um checklist que criei, cobrindo o impacto social do caso de uso, os resultados dos testes de viés, o nível de interpretabilidade do modelo e o plano de monitoramento contínuo.",
        "q_en": "How did the AI Ethics Committee operate in practice?",
        "a_en": "The committee met monthly and functioned as a 'quality gate.' No AI model went into production without its formal approval. The approval criteria were based on a checklist I created, covering the social impact of the use case, the results of the bias tests, the level of interpretability of the model, and the continuous monitoring plan."
    },
    {
        "q": "Como você se mantém atualizado sobre um campo que evolui tão rápido como a ética em IA?",
        "a": "Eu mantenho uma rotina de aprendizado contínuo. Sigo ativamente o trabalho de pesquisadores e instituições como o ‘AI Now Institute’ e o ‘Partnership on AI’, leio artigos científicos e participo de webinars. Além disso, mantenho uma rede de contatos com outros profissionais da área para trocar experiências e desafios, o que é fundamental para me manter na vanguarda.",
        "q_en": "How do you stay updated on a field that evolves as fast as AI ethics?",
        "a_en": "I maintain a routine of continuous learning. I actively follow the work of researchers and institutions like the 'AI Now Institute' and the 'Partnership on AI,' read scientific articles, and participate in webinars. In addition, I maintain a network of contacts with other professionals in the field to exchange experiences and challenges, which is essential to keep me at the forefront."
    },
    {
        "q": "O que significa ser ‘humilde e ponderado’ ao lidar com IA na prática?",
        "a": "Significa reconhecer que os dados são um reflexo do mundo, com todos os seus vieses, e não a verdade absoluta. É ter a humildade de saber que meu modelo pode estar errado ou ser injusto, e a ponderação de criar sistemas robustos para auditar, monitorar e corrigir esses erros continuamente, em vez de confiar cegamente na tecnologia.",
        "q_en": "What does being 'humble and thoughtful' when dealing with AI in practice mean?",
        "a_en": "It means recognizing that data is a reflection of the world, with all its biases, and not the absolute truth. It is having the humility to know that my model may be wrong or unfair, and the thoughtfulness to create robust systems to audit, monitor, and continuously correct these errors, rather than blindly trusting the technology."
    },
    {
        "q": "Quem fazia parte do ‘Comitê de Ética em IA’ e por que você escolheu essa composição?",
        "a": "Era um grupo multidisciplinar que eu fiz questão de montar. Incluía cientistas de dados, líderes de negócio, representantes da área jurídica, compliance, auditoria e, o mais importante, um membro do comitê de relacionamento com o cooperado, que trazia a voz do cliente para a discussão. Essa diversidade garantia que considerássemos o impacto de múltiplas perspectivas e evitássemos pontos cegos.",
        "q_en": "Who was part of the 'AI Ethics Committee' and why did you choose this composition?",
        "a_en": "It was a multidisciplinary group that I made a point of assembling. It included data scientists, business leaders, representatives from the legal, compliance, and audit areas, and, most importantly, a member of the cooperative member relations committee, who brought the customer's voice to the discussion. This diversity ensured that we considered the impact from multiple perspectives and avoided blind spots."
    }
]
};

export default case_3;
