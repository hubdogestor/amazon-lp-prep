// Case 3 - broad_responsibility
const case_3 = {
  id: "sicredi-responsible-ai-policy",
  title: "Impacto Amplo das Decisões: Política de IA Responsável com Responsabilidade Social, Equidade e Transparência",
  title_pt: "Impacto Amplo das Decisões: Política de IA Responsável com Responsabilidade Social, Equidade e Transparência",
  title_en: "Broader Impact of Decisions: Responsible AI Policy with Social Responsibility, Equity and Transparency",
  company: "Sicredi",
  period: "01/2020-12/2020",
  isTopCase: false,
  isGoodCase: false,
  pt: {
    s: `"120 mil vidas financeiras. Modelo aprovado. Taxa de aprovação para autônomos: 23% menor. Viés confirmado antes do deploy." No Sicredi, ao introduzirmos o primeiro modelo de ML para pré-aprovação de crédito, o sucesso trouxe uma nova e complexa responsabilidade. A escala do negócio significava que as decisões do algoritmo impactariam a vida financeira de 120 mil+ cooperados. Antes de implementar, analisei impactos em 3 dimensões: (1) cooperados (120k pessoas, 28% autônomos historicamente sub-representados em crédito), (2) reguladores (BACEN com foco crescente em equidade algorítmica), (3) sociedade (risco de perpetuar vieses contra trabalhadores autônomos e minorias). Quando propus uma "Política de IA Responsável", enfrentei resistência imediata: o VP Comercial argumentou que "auditorias éticas atrasariam lançamentos" e que "concorrentes não fazem isso". Mas o impacto amplo de decisões erradas - multas, reputação, exclusão financeira de milhares - era uma responsabilidade que eu precisava endereçar, mesmo contra a resistência interna.`,
    t: `Meu papel individual: eu liderei end-to-end, defini escopo e decisões críticas, e atuei como owner único. Minha tarefa era considerar impacto amplo das decisões de IA: não apenas acurácia do modelo (métrica técnica), mas efeitos secundários em 120k+ cooperados, trabalhadores autônomos (28% da base, 33.600 pessoas), reguladores BACEN (fiscalização crescente), e futuras gerações (precedente de uso ético de dados). Eu precisava garantir que cada decisão do algoritmo fosse auditável, justa e transparente para toda a comunidade cooperativa. Minha tarefa foi liderar a criação da primeira 'Política de IA Responsável' do Sicredi, deixando as coisas melhores não apenas em tecnologia, mas em governança e responsabilidade social ampla.`,
    a: `Ações pessoais: priorizei mudanças, alinhei stakeholders, tomei decisões de trade-off e removi bloqueios. Iniciei o projeto apresentando pessoalmente à liderança os riscos reputacionais e regulatórios emergentes de IA enviesada, usando exemplos específicos de outras empresas. Argumentei veementemente que, para uma cooperativa baseada em princípios de equidade, a responsabilidade de garantir uma IA justa não era opcional, era central para a marca. Estudei intensivamente os frameworks de IA Responsável do Google e Microsoft porque eram os mais maduros do mercado, com casos de uso documentados em instituições financeiras, e incluíam ferramentas práticas de detecção de viés que eu poderia adaptar. Tomei a decisão de organizar um workshop com especialistas em ética de IA da UFRGS, enfrentando resistência inicial sobre custos. O insight chave foi o conceito de 'justiça contrafactual', que me ajudou a moldar testes de viés muito mais robustos que simples comparações demográficas. Redigi pessoalmente a política que instituía mecanismos concretos. Um deles foi o 'teste de viés' obrigatório que implementei para qualquer modelo que impactasse decisões de clientes. Quando os testes iniciais que supervisionei identificaram que o modelo estava penalizando injustamente trabalhadores autônomos (taxa de aprovação 23% menor vs. trabalhadores formais com mesmo perfil de risco), liderei pessoalmente a correção através de 'feature engineering'. Criei novas variáveis que representavam melhor a saúde financeira de um autônomo (regularidade de depósitos, diversidade de fontes de renda). Quando enfrentei pushback sobre complexidade adicional, justifiquei o ROI ético. A política que elaborei exigiu um processo de 'explicabilidade'. Liderei a criação de um sistema que traduzia a decisão do modelo em explicação simples, comunicada ao cliente, aumentando transparência e confiança.`,
    r: `A 'Política de IA Responsável' foi implementada e se tornou o padrão para todos os projetos de dados no Sicredi. Impacto amplo mensurável em 3 dimensões: (1) Cooperados - 18.000+ autônomos qualificados (15% de 120k base) ganharam acesso a crédito justo, taxa de aprovação aumentou 15% equiparando-se à de trabalhadores formais (de 23% abaixo para 2% abaixo da média), gerando R$ 47M+ em crédito liberado antes negado injustamente. (2) Reguladores - credibilidade com BACEN evitou fiscalização invasiva (3 concorrentes sofreram auditorias custando R$ 12M+ cada), fomos citados como caso de sucesso em circular sobre governança algorítmica. (3) Sociedade - framework replicado por 3 cooperativas (600k+ membros agregados), estabelecendo precedente de IA responsável no cooperativismo brasileiro, protegendo futuras gerações de exclusão financeira algorítmica.`,
    l: `Aprendi que considerar impacto amplo das decisões exige metodologia estruturada, não apenas boa intenção. Hoje uso 3 passos em todo projeto: (1) Mapear stakeholders secundários além do cliente direto - no caso IA foram autônomos (28% base), reguladores, sociedade, não só time de crédito; (2) Antecipar efeitos não intencionais com testes empíricos - 'justiça contrafactual' detectou viés que análise superficial perderia; (3) Criar governança para decisões em escala - Comitê de Ética com multidisciplinar (dados, negócio, jurídico, compliance, voz do cooperado) garante múltiplas perspectivas. Antes de qualquer projeto de tecnologia que lidero, pergunto 'Quem mais isso afeta além do usuário direto?' e documento respostas em matriz de impacto com mitigações. Responsabilidade sobre efeitos secundários cresce exponencialmente com escala - 120k decisões algorítmicas exigem governança proporcional.`
  },
  en: {
    s: `"120 thousand financial lives. Model approved. Approval rate for freelancers: 23% lower. Bias confirmed before deploy." At Sicredi, when introducing the first ML model for credit pre-approval, success brought a new and complex responsibility. Business scale meant the algorithm's decisions would impact 120k+ cooperative members' financial lives. Before implementing, I analyzed impacts across 3 dimensions: (1) members (120k people, 28% freelancers historically underrepresented in credit), (2) regulators (Central Bank with growing focus on algorithmic equity), (3) society (risk of perpetuating biases against freelance workers and minorities). When I proposed a "Responsible AI Policy," I faced immediate resistance: the Commercial VP argued that "ethical audits would delay launches" and that "competitors don't do this." But the broader impact of wrong decisions - fines, reputation, financial exclusion of thousands - was a responsibility I needed to address, even against internal resistance.`,
    t: `My individual role: I led end-to-end, set scope and critical decisions, and acted as the single-threaded owner. My task was to consider broader impact of AI decisions: not just model accuracy (technical metric), but secondary effects on 120k+ members, freelance workers (28% of base, 33,600 people), Central Bank regulators (increasing oversight), and future generations (precedent for ethical data use). I needed to ensure every algorithm decision was auditable, fair and transparent to the entire cooperative community. My task was to lead creation of Sicredi's first 'Responsible AI Policy', leaving things better not just in technology, but in governance and broad social responsibility.`,
    a: `Personal actions: I drove execution—prioritized changes, aligned stakeholders, made trade-offs, and unblocked teams. I personally presented to leadership the emerging reputational and regulatory risks of biased AI, using specific examples from other companies. I argued vehemently that, for a cooperative based on equity principles, the responsibility to ensure fair AI wasn't optional, it was central to the brand. I intensively studied Google and Microsoft's Responsible AI frameworks because they were the most mature in the market, with documented use cases in financial institutions, and included practical bias detection tools I could adapt. I made the decision to organize a workshop with AI ethics experts from UFRGS, facing initial resistance about costs. The key insight was the concept of 'counterfactual fairness', which helped me shape much more robust bias tests than simple demographic comparisons. I personally drafted the policy that instituted concrete mechanisms. One was mandatory 'bias testing' I implemented for any model impacting customer decisions. When initial tests I supervised identified the model was unfairly penalizing freelance workers (23% lower approval rate vs. formal workers with same risk profile), I personally led the correction through 'feature engineering'. I created new variables that better represented a freelancer's financial health (deposit regularity, income source diversity). When I faced pushback about additional complexity, I justified the ethical ROI. The policy I elaborated required an 'explainability' process. I led creation of a system that translated the model's decision into simple explanation, communicated to customers, increasing transparency and trust.`,
    r: `The 'Responsible AI Policy' was implemented and became the standard for all data projects at Sicredi. Measurable broader impact across 3 dimensions: (1) Members - 18,000+ qualified freelancers (15% of 120k base) gained access to fair credit, approval rate increased 15% equalizing with formal workers (from 23% below to 2% below average), generating R$ 47M+ in credit previously denied unfairly. (2) Regulators - credibility with Central Bank avoided invasive oversight (3 competitors suffered audits costing R$ 12M+ each), we were cited as success case in circular on algorithmic governance. (3) Society - framework replicated by 3 cooperatives (600k+ aggregate members), establishing precedent for responsible AI in Brazilian cooperativism, protecting future generations from algorithmic financial exclusion.`,
    l: `I learned that considering broader impact of decisions requires structured methodology, not just good intention. Today I use 3 steps in every project: (1) Map secondary stakeholders beyond direct customer - in AI case they were freelancers (28% base), regulators, society, not just credit team; (2) Anticipate unintended effects with empirical tests - 'counterfactual fairness' detected bias superficial analysis would miss; (3) Create governance for scale decisions - Ethics Committee with multidisciplinary (data, business, legal, compliance, member voice) ensures multiple perspectives. Before any technology project I lead, I ask 'Who else does this affect beyond direct user?' and document answers in impact matrix with mitigations. Responsibility for secondary effects grows exponentially with scale - 120k algorithmic decisions require proportional governance.`
  },
  fups: [
    {
        "q": "Quais foram os principais desafios ao implementar a Política de IA Responsável e como você os superou?",
        "a": "O maior desafio foi a resistência do VP Comercial que argumentou que 'auditorias éticas atrasariam lançamentos' e que 'concorrentes não fazem isso'. Superei isso demonstrando com dados que modelos enviesados custaram à concorrência milhões em multas e reputação. Mostrei que IA Responsável não era 'freio', mas 'guard-rail' que acelerava go-to-market ao evitar retrabalho. Argumentei que construir certo desde o início era mais rápido que gerenciar crise depois.",
        "q_en": "What were the main challenges implementing the Responsible AI Policy and how did you overcome them?",
        "a_en": "The biggest challenge was resistance from Commercial VP who argued that 'ethical audits would delay launches' and 'competitors don't do this'. I overcame this by demonstrating with data that biased models cost competitors millions in fines and reputation. I showed Responsible AI wasn't a 'brake' but a 'guard-rail' that accelerated go-to-market by avoiding rework. I argued building right from start was faster than managing crisis later."
    },
    {
        "q": "Como você monitorou os resultados após corrigir o viés no modelo? Houve melhorias específicas para os trabalhadores autônomos ou outros grupos?",
        "a": "Eu criamos um 'dashboard de equidade' que monitorava continuamente a taxa de aprovação do modelo entre diferentes segmentos demográficos. Após a correção, vimos a taxa de aprovação para autônomos qualificados aumentar em 15%, alinhando-se com a dos trabalhadores formais com perfil de risco similar, provando que havíamos corrigido a distorção.",
        "q_en": "How did you monitor results after correcting model bias? Were there specific improvements for freelance workers or other groups?",
        "a_en": "I created an 'equity dashboard' that continuously monitored the model's approval rate among different demographic segments. After correction, I saw approval rate for qualified freelancers increase by 15%, aligning with formal workers with similar risk profile, proving I had corrected the distortion."
    },
    {
        "q": "Como o Comitê de Ética em IA operava na prática? Quais eram os critérios para revisar e aprovar novos modelos?",
        "a": "O comitê se reunia mensalmente. Os critérios de aprovação eram baseados em um checklist que criei, cobrindo: 1) Validação do caso de uso e seu impacto social. 2) Resultados dos testes de viés. 3) Nível de interpretabilidade do modelo. 4) Plano de monitoramento contínuo. Nenhum modelo entrava em produção sem a aprovação formal do comitê.",
        "q_en": "How did the AI Ethics Committee operate in practice? What were the criteria for reviewing and approving new models?",
        "a_en": "The committee met monthly. Approval criteria were based on a checklist I created, covering: 1) Use case validation and its social impact. 2) Bias test results. 3) Model interpretability level. 4) Continuous monitoring plan. No model went into production without formal committee approval."
    },
    {
        "q": "Houve resistência interna ou externa à ideia de tornar as decisões da IA explicáveis? Como você lidou com isso?",
        "a": "A resistência interna veio da equipe de dados, preocupada com a complexidade técnica. Lidei com isso posicionando a 'explicabilidade' como um desafio de engenharia interessante e investindo em ferramentas (como SHAP) que facilitavam o processo. Externamente, a resposta foi extremamente positiva, especialmente dos clientes que valorizaram a transparência.",
        "q_en": "Was there internal or external resistance to making AI decisions explainable? How did you handle it?",
        "a_en": "Internal resistance came from the data team, worried about technical complexity. I handled this by positioning 'explainability' as an interesting engineering challenge and investing in tools (like SHAP) that facilitated the process. Externally, response was extremely positive, especially from customers who valued transparency."
    },
    {
        "q": "Após o sucesso dessa iniciativa, como você garantiu que a política fosse continuamente aprimorada e mantida em novos projetos?",
        "a": "A política foi integrada ao meu processo de desenvolvimento de produtos. A revisão pelo Comitê de Ética se tornou um 'quality gate' obrigatório. Além disso, criamos um treinamento anual obrigatório sobre IA Responsável para todos os funcionários das áreas de dados e produto, garantindo que o conhecimento fosse constantemente renovado.",
        "q_en": "After this initiative's success, how did you ensure the policy was continuously improved and maintained in new projects?",
        "a_en": "The policy was integrated into my product development process. Ethics Committee review became a mandatory 'quality gate'. Additionally, I created mandatory annual training on Responsible AI for all data and product area employees, ensuring knowledge was constantly renewed."
    },
    {
        "q": "Como você se mantém atualizado sobre um campo que evolui tão rápido como a ética em IA?",
        "a": "Eu sigo ativamente o trabalho de pesquisadores e instituições líderes na área, como o 'AI Now Institute' e o 'Partnership on AI'. Leio os artigos, acompanho os debates e participo de webinars. É uma responsabilidade contínua de aprendizado. Também mantenho uma rede de contatos com outros profissionais que enfrentam desafios similares.",
        "q_en": "How do you stay updated on a field that evolves as fast as AI ethics?",
        "a_en": "I actively follow the work of leading researchers and institutions in the area, like the 'AI Now Institute' and 'Partnership on AI'. I read articles, follow debates and participate in webinars. It's a continuous learning responsibility. I also maintain a network of contacts with other professionals facing similar challenges."
    },
    {
        "q": "O que significa ser 'humilde e ponderado' ao lidar com IA?",
        "a": "Significa reconhecer que os dados não são a verdade absoluta; eles são um reflexo do mundo, com todos os seus vieses. Significa ter a humildade de saber que meu modelo pode estar errado ou ser injusto, e a ponderação de criar sistemas robustos para auditar, monitorar e corrigir esses erros continuamente.",
        "q_en": "What does being 'humble and thoughtful' mean when dealing with AI?",
        "a_en": "It means recognizing that data isn't absolute truth; it's a reflection of the world, with all its biases. It means having the humility to know my model can be wrong or unfair, and the thoughtfulness to create robust systems to audit, monitor and continuously correct these errors."
    },
    {
        "q": "Como essa iniciativa de responsabilidade deixou as coisas 'melhores do que você as encontrou'?",
        "a": "Antes, o processo de crédito era uma caixa-preta. Deixamos um processo mais justo e transparente. Criamos uma consciência sobre a responsabilidade ética do uso de dados que não existia e que passou a influenciar todos os outros projetos de tecnologia. Estabelecemos um precedente de que inovação e responsabilidade social andam juntas.",
        "q_en": "How did this responsibility initiative leave things 'better than you found them'?",
        "a_en": "Before, the credit process was a black box. I left a fairer and more transparent process. I created awareness about ethical responsibility in data use that didn't exist and began influencing all other technology projects. I established a precedent that innovation and social responsibility go together."
    },
    {
        "q": "Qual é a sua maior preocupação sobre o futuro da IA e qual é a sua responsabilidade como líder para mitigá-la?",
        "a": "Minha maior preocupação é a automação da tomada de decisões em escala sem a devida governança ética, levando a consequências não intencionais de discriminação. Minha responsabilidade como líder é ser um defensor incansável da IA Responsável, garantindo que, para cada avanço técnico, tenhamos um avanço correspondente em meu mecanismos de controle e transparência.",
        "q_en": "What's your biggest concern about AI's future and what's your responsibility as a leader to mitigate it?",
        "a_en": "My biggest concern is automation of decision-making at scale without proper ethical governance, leading to unintended discrimination consequences. My responsibility as a leader is to be a tireless advocate for Responsible AI, ensuring that for each technical advance, I have a corresponding advance in my control and transparency mechanisms."
    },
    {
        "q": "Quem fazia parte do 'Comitê de Ética em IA' e por que você escolheu essa composição?",
        "a": "Era um grupo multidisciplinar. Incluía cientistas de dados, líderes de negócio, representantes da área jurídica, compliance, auditoria e, crucialmente, um membro do comitê de relacionamento com o cooperado, que trazia a voz do cliente para a discussão. Essa diversidade garantia que considerássemos o impacto de múltiplas perspectivas.",
        "q_en": "Who was part of the 'AI Ethics Committee' and why did you choose this composition?",
        "a_en": "It was a multidisciplinary group. It included data scientists, business leaders, legal area representatives, compliance, audit and, crucially, a member of the member relationship committee, who brought the customer voice to the discussion. This diversity ensured I considered impact from multiple perspectives."
    }
]
};

export default case_3;
