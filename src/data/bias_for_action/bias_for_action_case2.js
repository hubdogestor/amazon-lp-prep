// Case 2 - bias_for_action (VERSÃO NATURAL)
const case_2 = {
  id: "sicredi-ml-credit-approval",
  title: "Quebrei resistência cultural de 23 anos e implementei ML em crédito com 30% menos rejeições",
  title_pt: "Quebrei resistência cultural de 23 anos e implementei ML em crédito com 30% menos rejeições",
  title_en: "Broke 23-year cultural resistance and implemented ML in credit with 30% fewer rejections",
  company: "Sicredi",
  period: "03/2021-11/2021",
  isTopCase: true,
  isGoodCase: false,
  pt: {
    s: `"18 mil pedidos no backlog. Perda de R$ 46 milhões por trimestre. Taxa de abandono 31%." Os números que apresentei ao comitê de crédito em março de 2021 revelavam uma crise silenciosa. Era eu, como Head de Produto Digital no Sicredi, enfrentando 23 anos de cultura conservadora: "Crédito rural não é fintech. Aqui conhecemos o cooperado pelo nome." O diretor de risco, veterano de três décadas, foi direto: "Machine learning vai aprovar quem não deveria e negar quem merece. Vou vetar qualquer automação." Simultaneamente, cooperados bombardeavam SAC reclamando de demora — análise manual levava 11 dias úteis quando concorrentes aprovavam em 2 horas. A pressão era brutal: 6,4 milhões de cooperados esperando agilidade, mas qualquer erro de crédito custaria milhões em inadimplência.`,
    t: `Meu escopo como Head de Produto cobria experiência digital, mas eu precisava resolver completamente essa resistência cultural. O desafio crítico era provar que ML poderia acelerar aprovações sem aumentar risco, quebrando décadas de desconfiança. Tracei três metas: (1) rodar piloto controlado em 30 dias mostrando que ML mantinha inadimplência abaixo de 2,1%, (2) criar guardrails transparentes que tranquilizassem risco, (3) escalar gradualmente até processar 80% dos pedidos automaticamente.`,
    a: `Minha estratégia foi começar pequeno e provar valor antes de pedir permissão total. Negociei piloto com 500 pedidos de baixo risco (até R$ 50K, score acima de 700), criando modelo híbrido onde ML sugeria e analista validava. Construí dashboard em tempo real mostrando cada decisão, taxa de concordância e impacto em inadimplência. Em 15 dias, ML acertou 94% das decisões que analistas tomariam, mas reduziu tempo de 11 para 2,3 dias. Quando diretor de risco viu os números, pediu expansão cautelosa. Criei três guardrails: (1) ML só aprovava até R$ 200K, (2) qualquer discordância ia para analista, (3) auditoria semanal de 100% das aprovações automáticas. Implementei feature flags para rollback instantâneo se inadimplência subisse 0,1%. Treinei 47 analistas no novo fluxo, criei alertas automáticos para casos edge e estabeleci ritual de revisão quinzenal com risco. Quando sistema sugeriu negar crédito para cooperado histórico, analista questionou; investigamos e descobrimos fraude de identidade — ML havia detectado padrão que humano perdeu.`,
    r: `Em oito meses, ML processava 73% dos pedidos automaticamente, tempo médio caiu de 11 para 1,8 dias, backlog despencou para 2.400 pedidos, e inadimplência manteve-se em 1,9% — abaixo da meta. Taxa de abandono despencou de 31% para 8%, geramos R$ 127 milhões adicionais em crédito aprovado e cortamos custo operacional em 42%. O diretor de risco, inicialmente cético, tornou-se advocate do modelo e pediu expansão para outros produtos. Mais importante: criamos cultura de experimentação controlada que foi replicada em seguros e investimentos.`,
    l: `Aprendi que quebrar resistência cultural não acontece com apresentações, mas com experimentos pequenos que geram confiança gradual. Quando mostro resultados incrementais e mantenho guardrails transparentes, consigo transformar céticos em advocates. Velocidade com segurança vence velocidade sem controle. Hoje, sempre que enfrento resistência a inovação, aplico o mesmo playbook: piloto pequeno, métricas claras, guardrails visíveis.`
  },
  en: {
    s: `"18,000 requests in backlog. BRL 46 million loss per quarter. 31% abandonment rate." The numbers I presented to the credit committee in March 2021 revealed a silent crisis. There I was, as Head of Digital Product at Sicredi, facing 23 years of conservative culture: "Rural credit isn't fintech. Here we know members by name." The risk director, a three-decade veteran, was direct: "Machine learning will approve who shouldn't and deny who deserves. I'll veto any automation." Simultaneously, members bombarded customer service complaining about delays — manual analysis took 11 business days when competitors approved in 2 hours. The pressure was brutal: 6.4 million members expecting agility, but any credit error would cost millions in defaults.`,
    t: `My scope as Head of Product covered digital experience, but I needed to completely resolve this cultural resistance. The critical challenge was proving ML could accelerate approvals without increasing risk, breaking decades of distrust. I set three goals: (1) run controlled pilot in 30 days showing ML kept defaults below 2.1%, (2) create transparent guardrails that would reassure risk, (3) scale gradually until processing 80% of requests automatically.`,
    a: `My strategy was starting small and proving value before asking for full permission. I negotiated a pilot with 500 low-risk requests (up to BRL 50K, score above 700), creating hybrid model where ML suggested and analyst validated. I built real-time dashboard showing each decision, agreement rate, and default impact. Within 15 days, ML matched 94% of decisions analysts would make, but reduced time from 11 to 2.3 days. When risk director saw the numbers, he requested cautious expansion. I created three guardrails: (1) ML only approved up to BRL 200K, (2) any disagreement went to analyst, (3) weekly audit of 100% automatic approvals. I implemented feature flags for instant rollback if defaults rose 0.1%. I trained 47 analysts in the new flow, created automatic alerts for edge cases, and established biweekly review ritual with risk. When system suggested denying credit to a historical member, analyst questioned; we investigated and discovered identity fraud — ML had detected pattern human missed.`,
    r: `Within eight months, ML processed 73% of requests automatically, average time dropped from 11 to 1.8 days, backlog plummeted to 2,400 requests, and defaults stayed at 1.9% — below target. Abandonment rate dropped from 31% to 8%, we generated additional BRL 127 million in approved credit, and cut operational cost by 42%. The risk director, initially skeptical, became model advocate and requested expansion to other products. Most importantly: we created controlled experimentation culture replicated in insurance and investments.`,
    l: `I learned that breaking cultural resistance doesn't happen with presentations, but with small experiments that build gradual trust. When I show incremental results and maintain transparent guardrails, I can transform skeptics into advocates. Speed with safety beats speed without control. Today, whenever I face innovation resistance, I apply the same playbook: small pilot, clear metrics, visible guardrails.`
  },
  fups: [
    { q: "Como você estruturou o piloto de 500 pedidos?", a: "Selecionei baixo risco (até R$ 50K, score >700), criei modelo híbrido ML+analista e dashboard em tempo real com cada decisão e concordância.", q_en: "How did you structure the 500-request pilot?", a_en: "Selected low risk (up to BRL 50K, score >700), created hybrid ML+analyst model and real-time dashboard with each decision and agreement." },
    { q: "Quais guardrails específicos você implementou?", a: "ML só aprovava até R$ 200K, discordância ia para analista, auditoria semanal de 100% das aprovações automáticas, e feature flags para rollback.", q_en: "Which specific guardrails did you implement?", a_en: "ML only approved up to BRL 200K, disagreement went to analyst, weekly audit of 100% automatic approvals, and feature flags for rollback." },
    { q: "Como você treinou os 47 analistas?", a: "Workshop de 2 dias sobre ML, simulação com casos reais, manual de edge cases e canal direto para dúvidas durante transição.", q_en: "How did you train the 47 analysts?", a_en: "2-day ML workshop, simulation with real cases, edge case manual, and direct channel for questions during transition." },
    { q: "Que métricas você monitorou em tempo real?", a: "Taxa de concordância ML vs analista, tempo de processamento, inadimplência por faixa, volume de rollbacks e satisfação do cooperado.", q_en: "Which metrics did you monitor in real time?", a_en: "ML vs analyst agreement rate, processing time, default by range, rollback volume, and member satisfaction." },
    { q: "Como você detectou a fraude de identidade?", a: "ML flagou padrão de comportamento inconsistente com histórico. Analista investigou e descobriu CPF clonado usado em múltiplas cooperativas.", q_en: "How did you detect the identity fraud?", a_en: "ML flagged behavior pattern inconsistent with history. Analyst investigated and found cloned ID used across multiple cooperatives." },
    { q: "Qual foi a reação inicial dos analistas?", a: "Medo de substituição. Resolvi posicionando ML como assistente, não substituto, e mostrando que detectava fraudes que eles perdiam.", q_en: "What was analysts' initial reaction?", a_en: "Fear of replacement. I solved by positioning ML as assistant, not substitute, and showing it detected frauds they missed." },
    { q: "Como você escalou de 500 para milhares de pedidos?", a: "Aumentei gradualmente: 500→2K→5K→15K, sempre validando inadimplência e ajustando guardrails conforme volume crescia.", q_en: "How did you scale from 500 to thousands of requests?", a_en: "Increased gradually: 500→2K→5K→15K, always validating defaults and adjusting guardrails as volume grew." },
    { q: "Que resistência você enfrentou durante implementação?", a: "Analistas seniores questionavam decisões, risco pedia mais controles, TI reclamava de performance. Resolvi com transparência total.", q_en: "What resistance did you face during implementation?", a_en: "Senior analysts questioned decisions, risk demanded more controls, IT complained about performance. Solved with total transparency." },
    { q: "Como você mediu ROI da automação?", a: "Calculei custo por análise (R$ 47→R$ 12), tempo economizado (9,2 dias), e receita adicional de R$ 127M por aprovações mais rápidas.", q_en: "How did you measure automation ROI?", a_en: "Calculated cost per analysis (BRL 47→BRL 12), time saved (9.2 days), and additional BRL 127M revenue from faster approvals." },
    { q: "Como isso impactou outros produtos?", a: "Modelo foi replicado em seguros (redução de 40% no tempo) e investimentos (automação de 60% das aplicações). Virou padrão da empresa.", q_en: "How did this impact other products?", a_en: "Model replicated in insurance (40% time reduction) and investments (60% application automation). Became company standard." }
  ]
};

export default case_2;
