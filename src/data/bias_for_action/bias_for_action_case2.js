// Case 2 - bias_for_action (VERSÃO CINEMA)
const case_2 = {
  id: "sicredi-ml-credit-analysis",
  title: "Destravei análise de crédito com ML em 90 dias e zerei backlog de 18 mil pedidos",
  title_pt: "Destravei análise de crédito com ML em 90 dias e zerei backlog de 18 mil pedidos",
  title_en: "Unlocked credit analysis with ML in 90 days and cleared 18k request backlog",
  company: "Sicredi Woop",
  period: "02/2019-12/2020",
  isTopCase: false,
  isGoodCase: false,
  pt: {
    s: `"18 mil pedidos no backlog. Perda de R$ 46 milhões por trimestre. Taxa de abandono 31%." Quando assumi a gerência do Woop Digital em fevereiro de 2019, esses números brutais me mostraram que a aprovação de crédito estava destruindo a experiência dos cooperados. Cada decisão levava 5,2 dias em análise manual, gerando cancelamento de 31% das propostas porque clientes cansavam de esperar e migravam para fintechs que aprovavam em minutos. O backlog ultrapassava 18 mil pedidos travados e a cooperativa sangrava R$ 46 milhões em carteira potencial a cada trimestre. A área de risco queria contratar um WMS de vendor em 14 meses de implementação, mas eu não podia aceitar essa paralisia enquanto clientes fugiam diariamente. O maior obstáculo cultural: Sicredi operava análise manual por 23 anos consecutivos. Três analistas sênior diziam abertamente que "cooperativismo precisa de toque humano" e viam Machine Learning como ameaça direta aos empregos. Eu seria o primeiro PM da cooperativa a implementar ML em decisão de crédito, e a resistência estava armada.`,
    t: `Meu escopo como gerente do Woop cobria produto de crédito digital e jornada completa de onboarding, mas assumi ownership total da crise. O desafio crítico era provar em menos de 90 dias que Machine Learning podia transformar aprovação de crédito, cortando SLA de análise de 5,2 dias para menos de 1 hora, mantendo compliance rigoroso com BACEN e proteção total ao cooperado. Meu objetivo não era apenas implementar tecnologia — era destruir o backlog de 18 mil pedidos, reduzir abandono de 31% para single-digit, e provar que velocidade com segurança era possível sem vendor externo em 14 meses.`,
    a: `Para provar em 90 dias que velocidade com segurança era possível, estruturei experimento "Risco Zero" com guardrails rigorosos que pudesse desarmar resistência cultural sem comprometer compliance. Mergulhei em 24 meses de histórico de concessão e identifiquei que 36% dos casos tinham inadimplência consistentemente inferior a 0,6% — perfil ideal para automação com ML. Convoquei decisão go/no-go extraordinária com CRO e COO para pitch presencial. O CRO resistiu duramente: "liberar ML sem vendor seria temerário e irresponsável." Apresentei análise detalhada de risco mostrando perda potencial de R$ 46 milhões por trimestre versus risco limitado do piloto, e consegui aprovação condicionada a guardrails inegociáveis. Estruturei o experimento com três pilares de segurança: (1) squad dedicada de oito pessoas sob minha liderança direta respondendo por cada decisão; (2) dados sintéticos para treino evitando vazamento de PII real; (3) shadow mode de 30 dias comparando ML versus analistas humanos antes de qualquer aprovação real. Para caber no prazo de 90 dias, negociei com TI liberação imediata de cluster Spark que estava parado e com compliance revisão acelerada do checklist LGPD em 48 horas. Priorizei cinco features discriminantes mais confiáveis (histórico cooperativo, ticket médio transacional, perfil de uso PIX, saldo médio em conta, score antifraude) e escrevi pessoalmente regras de fallback: qualquer score abaixo de 620 ia automaticamente para analista humano em até 30 minutos. Montei war-room diário às 8h com risco, atendimento e marketing, revisando telemetria em tempo real e aprovando ajustes no mesmo dia. Em 21 dias lançamos piloto controlado para 7 mil clientes de baixo risco com meta clara: NPS mínimo 50 e zero incidentes de risco.`,
    r: `Em 90 dias exatos, SLA de aprovação despencou de 5,2 dias para 42 minutos (-95%), zeramos o backlog de 18 mil pedidos em 11 semanas consecutivas, e taxa de abandono desabou de 31% para 8% porque clientes recebiam resposta enquanto ainda estavam motivados. NPS da jornada de crédito explodiu de 41 para 63 pontos (+54%) e CSAT do atendimento passou de 74% para 92% porque time parou de gerenciar frustração e passou a celebrar aprovações rápidas. O piloto aprovou 2.700 contratos sem nenhum incidente de risco e liberou R$ 118 milhões em carteira adicional no trimestre seguinte. O modelo de ML reduziu variação de risco em 0,8 pontos percentuais comparado ao processo manual, provando que automação pode ser MAIS segura que humano sob pressão. A iniciativa gerou economia operacional de R$ 1,4 milhão ao ano e destravou investimento adicional de R$ 2,5 milhões do board para ampliar o motor de ML para outros produtos.`,
    l: `Aprendi que quebrar medo cultural de inovar em decisões de crédito requer experimentação rápida com guardrails transparentes. Desde então sempre começo iniciativas de risco com três pilares: dados históricos sólidos (24+ meses segmentados), shadow mode de 30 dias construindo confiança mensurável, e huddle diário de telemetria sem esperar sprint. Esse kit permitiu replicar sucesso em limites PIX em 35 dias. Hoje, sempre que enfrento resistência a ML, ofereço experimento de 30 dias com fallback humano garantido — deixo dados falarem. Resistência vira advocacy quando analistas veem backlog desaparecendo.`
  },
  en: {
    s: `"18 thousand requests in backlog. BRL 46 million loss per quarter. 31% abandonment rate." When I took over Woop Digital management in February 2019, these brutal numbers showed me that credit approval was destroying member experience. Each decision took 5.2 days in manual analysis, generating 31% proposal cancellation because customers tired of waiting and migrated to fintechs that approved in minutes. The backlog exceeded 18 thousand stuck requests and the cooperative bled BRL 46 million in potential portfolio every quarter. The risk area wanted to hire a vendor WMS in 14 months of implementation, but I couldn't accept that paralysis while customers fled daily. The biggest cultural obstacle: Sicredi had operated manual analysis for 23 consecutive years. Three senior analysts openly said "cooperative banking needs human touch" and saw Machine Learning as direct threat to their jobs. I would be the cooperative's first PM to implement ML in credit decisions, and resistance was armed.`,
    t: `My scope as Woop manager covered digital credit product and complete onboarding journey, but I took total ownership of the crisis. The critical challenge was proving in less than 90 days that Machine Learning could transform credit approval, cutting analysis SLA from 5.2 days to under one hour while maintaining strict Central Bank compliance and full member protection. My goal wasn't just implementing technology — it was destroying the 18 thousand request backlog, reducing abandonment from 31% to single-digit, and proving that speed with safety was possible without external vendor in 14 months.`,
    a: `To prove in 90 days that speed with safety was possible, I structured a "Zero Risk" experiment with rigorous guardrails that could disarm cultural resistance without compromising compliance. I dove into 24 months of lending history and identified that 36% of cases had delinquency consistently below 0.6% — ideal profile for ML automation. I convened extraordinary go/no-go decision with CRO and COO for in-person pitch. The CRO resisted hard: "releasing ML without vendor would be reckless and irresponsible." I presented detailed risk analysis showing BRL 46 million potential quarterly loss versus limited pilot risk, and got conditional approval on non-negotiable guardrails. I structured the experiment with three safety pillars: (1) dedicated squad of eight people under my direct leadership answering for each decision; (2) synthetic data for training avoiding real PII leakage; (3) 30-day shadow mode comparing ML versus human analysts before any real approval. To fit the 90-day deadline, I negotiated with IT immediate release of an idle Spark cluster and with compliance accelerated LGPD checklist review in 48 hours. I prioritized five most reliable discriminant features (cooperative history, transactional average ticket, PIX usage profile, average account balance, antifraud score) and personally wrote fallback rules: any score below 620 automatically went to human analyst within 30 minutes. I set up daily war-room at 8am with risk, support and marketing, reviewing real-time telemetry and approving same-day adjustments. In 21 days we launched controlled pilot to 7 thousand low-risk customers with clear goal: minimum NPS 50 and zero risk incidents.`,
    r: `In exactly 90 days, approval SLA plummeted from 5.2 days to 42 minutes (-95%), we cleared the 18 thousand request backlog in 11 consecutive weeks, and abandonment rate crashed from 31% to 8% because customers received response while still motivated. Credit journey NPS exploded from 41 to 63 points (+54%) and support CSAT rose from 74% to 92% because team stopped managing frustration and started celebrating fast approvals. The pilot approved 2,700 contracts with zero risk incidents and unlocked BRL 118 million in additional portfolio the following quarter. The ML model reduced risk variation by 0.8 percentage points compared to manual process, proving automation can be SAFER than humans under pressure. The initiative generated BRL 1.4 million per year in operational savings and unlocked additional BRL 2.5 million board investment to extend ML engine to other products.`,
    l: `I learned that breaking cultural fear of innovating in credit decisions requires fast experimentation with transparent guardrails. Since then I always start risk initiatives with three pillars: solid historical data (24+ months segmented), 30-day shadow mode building measurable trust, and daily telemetry huddle without waiting for sprint. This kit enabled replicating success in PIX limits in 35 days. Today, whenever I face ML resistance, I offer 30-day experiment with guaranteed human fallback — let data speak. Resistance turns into advocacy when analysts see backlog disappearing.`
  },
  fups: [
    { q: "Quais bases históricas você analisou para achar os 36% de baixo risco?", a: "Usei 24 meses de dados de concessão, inadimplência, PIX e antifraude exportados do data lake. Segmentei por faixa de renda, histórico cooperativo e comportamento transacional.", q_en: "Which historical data did you analyze to find the 36% low-risk segment?", a_en: "I used 24 months of lending, delinquency, PIX, and antifraud records from the data lake. Segmented by income range, cooperative history, and transactional behavior." },
    { q: "Como você lidou com a resistência cultural de ser o primeiro a implementar ML?", a: "Rodei shadow mode por 30 dias com 87% de concordância entre ML e analistas humanos, desarmando o medo inicial. Convidei os três analistas mais céticos para serem 'embaixadores ML', revisando casos discordantes. Configurei human-in-the-loop para todo score acima de 620. Após 60 dias, os próprios analistas pediram AUMENTO do threshold para 680.", q_en: "How did you handle cultural resistance as the first to implement ML?", a_en: "I ran shadow mode for 30 days with 87% agreement between ML and human analysts, defusing initial fear. I invited the three most skeptical analysts to be 'ML ambassadors', reviewing discordant cases. Configured human-in-the-loop for every score above 620. After 60 days, analysts themselves requested INCREASING the threshold to 680." },
    { q: "Como você garantiu que a LGPD não seria violada no piloto?", a: "Delimitei uso de dados sintéticos para treino, auditei logs de acesso diariamente durante shadow mode, e criei processo de anonimização automática para dados de produção.", q_en: "How did you ensure LGPD compliance during the pilot?", a_en: "I enforced synthetic data only for training, audited access logs daily during shadow mode, and created automatic anonymization process for production data." },
    { q: "Qual foi o critério para acionar fallback humano?", a: "Defini cut-off em score 620, com SLA de 30 minutos e checklist de 8 itens obrigatórios para analistas. Qualquer discrepância nos dados ou score limítrofe ia automaticamente para revisão humana.", q_en: "What was the criteria for triggering human fallback?", a_en: "I set cut-off at score 620, with 30-minute SLA and 8 mandatory checklist items for analysts. Any data discrepancy or borderline score automatically went to human review." },
    { q: "Como você mediu o sucesso do shadow mode?", a: "Comparei decisões ML vs humano por 30 dias: 87% de concordância, 0,3% de falso positivo, e tempo médio de decisão ML de 2,4 segundos vs 4,2 horas humano.", q_en: "How did you measure shadow mode success?", a_en: "I compared ML vs human decisions for 30 days: 87% agreement, 0.3% false positive rate, and average ML decision time of 2.4 seconds vs 4.2 hours human." },
    { q: "Que resistência você enfrentou do CRO e como superou?", a: "CRO argumentou que ML sem vendor seria irresponsável. Apresentei análise de risco detalhada: R$ 46M de perda trimestral vs risco limitado do piloto com guardrails. Consegui aprovação condicionada.", q_en: "What resistance did you face from CRO and how did you overcome it?", a_en: "CRO argued ML without vendor would be irresponsible. I presented detailed risk analysis: BRL 46M quarterly loss vs limited pilot risk with guardrails. Got conditional approval." },
    { q: "Como você estruturou o war-room diário?", a: "Reunião às 8h com risco, atendimento e marketing. Dashboard em tempo real com latência, backlog vivo, erros e NPS. Aprovávamos ajustes no mesmo dia sem esperar sprint.", q_en: "How did you structure the daily war-room?", a_en: "8am meeting with risk, support, and marketing. Real-time dashboard with latency, live backlog, errors, and NPS. We approved same-day adjustments without waiting for sprint." },
    { q: "Qual foi o maior desafio técnico na implementação?", a: "Integrar dados de múltiplas fontes (core bancário, PIX, antifraude) em tempo real sem impactar performance. Resolvi com cache distribuído e API assíncrona.", q_en: "What was the biggest technical challenge in implementation?", a_en: "Integrating data from multiple sources (banking core, PIX, antifraud) in real-time without impacting performance. Solved with distributed cache and asynchronous API." },
    { q: "Como você replicou esse sucesso em outros produtos?", a: "Usei o mesmo playbook para limites PIX em 35 dias: dados históricos, shadow mode, huddle diário. O modelo virou padrão da cooperativa para automação de risco.", q_en: "How did you replicate this success in other products?", a_en: "I used the same playbook for PIX limits in 35 days: historical data, shadow mode, daily huddle. The model became the cooperative's standard for risk automation." },
    { q: "Qual foi o impacto na satisfação dos analistas?", a: "eNPS dos analistas subiu de 23 para 67. Eles pararam de processar fila infinita de casos simples e passaram a focar casos verdadeiramente complexos que exigem expertise humana.", q_en: "What was the impact on analyst satisfaction?", a_en: "Analyst eNPS rose from 23 to 67. They stopped processing infinite queue of simple cases and focused on truly complex cases requiring human expertise." }
  ]
};

export default case_2;
