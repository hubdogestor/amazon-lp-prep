{
  "original": {
    "id": "long-term-tradeoff",
    "title": "Assumi Trade-off: Menos Escopo Agora por Maior Robustez",
    "title_pt": "Assumi Trade-off: Menos Escopo Agora por Maior Robustez",
    "title_en": "Took the Trade-off: Less Scope Now for Greater Robustness",
    "company": "Bradesco Next",
    "period": "07/2017-12/2017",
    "isTopCase": false,
    "isGoodCase": false,
    "pt": {
      "s": "\"Vamos lançar todas as 14 features na Black Friday — marketing já prometeu.\" A frase do CPO em reunião executiva ignorava os dados brutais: 680 ms de latência (+45%), 27 incidentes P1 no backlog, chargebacks crescendo 19%/mês, e alerta do NOC de que 8K TPS derrubariam o core legado a 92% CPU, comprometendo 3,5 milhões de transações/dia para 1,2 milhão de clientes. Stakes: lançar tudo sem hardening = R$ 24M em perdas potenciais (multas + chargebacks + churn); cortar escopo = enfrentar CPO + marketing + promessas públicas. Dilema de ownership: proteger 1,2 milhão de clientes com decisão impopular ou ceder à pressão e arriscar colapso na Black Friday.\n\nEu liderava a integração de pagamentos no banco digital Next quando o squad planejava lançar 14 features em uma única release para a Black Friday. Eu enxergava latência média em 680 ms (+45%), backlog com 27 incidentes P1 e chargebacks crescendo 19% ao mês. Eu recebi alerta do NOC de que sob pico de 8 mil transações por segundo o core legado bateria 92% de CPU e poderia derrubar 3,5 milhões de transações por dia. O CPO insistia em manter o roadmap completo porque o marketing já prometera as novidades para 1,2 milhão de clientes.",
      "t": "O desafio crítico que enfrentei foi assumir ownership total do core — além do meu escopo formal de integrações — e tomar decisão impopular de cortar 9 de 14 features para proteger 1,2 milhão de clientes de colapso iminente na Black Friday.\n\nMeu escopo formal cobria integrações com parceiros, mas eu assumi ownership total do core. Eu estabeleci metas: manter disponibilidade acima de 99,9%, reduzir chargebacks em pelo menos 15% e liberar a release em duas ondas somente quando os controles críticos passassem em testes de carga. Eu avisei o CEO que cortaria a primeira onda para cinco features essenciais e entregaria o restante quando os gates estivesse verdes.",
      "a": "Minha abordagem foi construir modelo de risco baseado em dados, formar tiger team multifuncional em 48h e negociar trade-off transparente com CEO/merchants usando evidências concretas de degradação sob carga.\n\nEu formei uma tiger team com SRE, risco e produto em 48 horas. (1) Eu modelei cenários financeiros mostrando perda potencial de R$ 24M em multas, chargebacks e churn se lançássemos tudo sem reforço. (2) Eu orquestrei testes de carga com Locust até 12 mil TPS e provei que aos 7.600 TPS o core travava por limite de pooling. (3) Eu reescrevi o plano em duas fases: fase um com cinco features críticas (PIX recorrente, limites dinâmicos, antifraude adaptativo, SLA de disputa, painel de cashback) e fase dois pós-hardening. (4) Eu implantei mecanismos: circuit breaker, 96 alertas Prometheus, feature flags por segmento e game days duas vezes por semana. (5) Eu negociei com marketing e compliance uma campanha trust-first baseada nas cinco features e um roadmap público ancorado em marcos de estabilidade. (6) Eu enfrentei resistência do CPO no comitê executivo mostrando heatmap com nove métricas críticas (CPU, latência p95, chargeback ratio, SLA antifraude) e votei pelo gate até que os riscos ficassem aceitáveis; o CEO apoiou ao ver o modelo risco versus NPS. (7) Eu sentei no call center e reuni os cinco maiores merchants (iFood, Magazine Luiza, Rappi, Uber, B2W) para explicar o plano, ajustar feature flags e garantir SLA dedicado durante o pico.",
      "r": "O impacto mensurável para 1,2 milhão de clientes — resultado direto do trade-off de cortar 9 features para garantir robustez — transformou decisão impopular em dividendos de longo prazo.\n\nEu estabilizei o core em 28 dias mantendo apenas cinco features: disponibilidade subiu de 99,2% para 99,97%, latência p95 caiu para 320 ms (-53%), incidentes P1 reduziram de 27 para quatro por mês e chargebacks baixaram 18%. Eu garanti que a Black Friday processasse 3,8 milhões de transações por dia sem degradação, elevei o NPS pós-evento de 61 para 79 e reduzi reclamações no BACEN em 42%. Eu liberei a fase dois 45 dias depois com zero incidentes críticos e instituí um Postmortem Council semanal para manter o aprendizado vivo. O trade-off de cortar escopo gerou dividendos de longo prazo: nos 18 meses seguintes, a plataforma manteve disponibilidade média de 99,96% (vs. 99,1% em plataformas concorrentes), reduziu tempo médio de recuperação (MTTR) de 47 para 8 minutos e permitiu escalar de 8K para 24K TPS sem reescrever core. O framework de resiliência que criei (circuit breaker + 96 alertas + game days) foi adotado por 12 squads e preveniu 8 incidentes críticos ao detectar degradação antes de impactar clientes. O CFO calculou que evitamos R$ 67M em perdas potenciais (chargebacks + multas + churn) ao longo de 2 anos.",
      "l": "A lição principal desse caso transformou minha compreensão de ownership: às vezes significa dizer não quando dados mostram que clientes pagariam o preço — liderar com evidências e mecanismos permanentes preserva confiança de longo prazo muito além de features incrementais.\n\nEu aprendi que ownership inclui dizer não quando os dados mostram que o cliente pagaria a conta. Eu comprovei que liderar com evidências, trazer o cliente para a mesa e deixar mecanismos permanentes preserva confiança. Três princípios guiam meu approach desde então: (1) Long-term robustez > short-term features: clientes preferem cinco funcionalidades estáveis a 14 instáveis, (2) Mecanismos de resiliência são investimento, não custo: circuit breaker + game days + Postmortem Council geraram ROI de 28:1 ao prevenir incidentes, (3) Trade-off transparente com dados constrói confiança: ao mostrar heatmap de risco ao CEO e merchants, transformei resistência em advocacy. Esse modelo foi replicado em PIX Phase 2 (cortei 6 de 11 features, entreguei 3 dias antes do deadline BACEN com 99,98% disponibilidade) e Open Finance (adiamos 4 integrações, zeramos incidentes P1 em homologação BCB). Eu transformei esse checklist no meu padrão: nunca commito deadline sem load test, risk model e gates objetivos. Assumir trade-off difícil no curto prazo me rendeu reputação de \"entrega com qualidade\" e foi citado pelo CEO como exemplo de \"ownership que protege o cliente\"."
    },
    "en": {
      "s": "\"Let's ship all 14 features for Black Friday — marketing already promised.\" The CPO's phrase in executive meeting ignored brutal data: 680 ms latency (+45%), 27 P1 incidents in backlog, chargebacks climbing 19%/month, and NOC warning that 8K TPS would crash legacy core at 92% CPU, compromising 3.5M transactions/day for 1.2M customers. Stakes: ship everything without hardening = R$24M in potential losses (penalties + chargebacks + churn); cut scope = face CPO + marketing + public promises. Ownership dilemma: protect 1.2M customers with unpopular decision or yield to pressure and risk Black Friday collapse.\n\nI was leading payments integration at Next digital bank when the squad planned to ship 14 features in a single release for Black Friday. I saw average latency at 680 ms (+45%), a backlog of 27 P1 incidents, and chargebacks climbing 19% month over month. The NOC warned me that under the 8K TPS peak the legacy core would hit 92% CPU and could knock out 3.5 million transactions per day. The CPO insisted on shipping the full roadmap because marketing had promised it to 1.2 million customers.",
      "t": "The critical challenge I faced was taking total ownership of the core — beyond my formal integrations scope — and making the unpopular decision to cut 9 of 14 features to protect 1.2M customers from imminent Black Friday collapse.\n\nMy formal remit covered partner integrations, but I took full ownership of the core. I set the goals: keep availability above 99.9%, cut chargebacks by at least 15%, and release in two waves only after critical controls passed load testing. I told the CEO I would trim the first wave to five essential features and deliver the rest once the gates were green.",
      "a": "My approach was to build data-driven risk model, form cross-functional tiger team in 48h, and negotiate transparent trade-off with CEO/merchants using concrete evidence of degradation under load.\n\nI formed a tiger team with SRE, risk, and product in 48 hours. (1) I built financial scenarios that showed a potential R$24M loss in penalties, chargebacks, and churn if we launched everything without hardening. (2) I orchestrated Locust load tests up to 12K TPS and proved the core stalled at 7,600 TPS because of pooling limits. (3) I rewrote the roadmap into two phases: phase one with five critical features (recurring PIX, dynamic limits, adaptive antifraud, dispute SLA automation, cashback dashboard) and phase two after hardening. (4) I implemented mechanisms: circuit breaker, 96 Prometheus alerts, segment-based feature flags, and twice-weekly game days. (5) I negotiated a trust-first campaign with marketing and compliance anchored on the five features and a public roadmap tied to stability milestones. (6) I faced the CPO pushback in the executive committee by presenting a heatmap with nine critical metrics (CPU, p95 latency, chargeback ratio, antifraud SLA), voting to hold the gate until the risk dropped; the CEO backed the decision after seeing the risk-versus-NPS model. (7) I took call-center shifts and met top merchants (iFood, Magazine Luiza, Rappi, Uber, B2W) to explain the plan, tune feature flags, and guarantee dedicated SLAs during the peak.",
      "r": "The measurable impact for 1.2M customers — direct result of the trade-off to cut 9 features for robustness — transformed unpopular decision into long-term dividends.\n\nBy holding the scope to five features I stabilized the core in 28 days: availability rose from 99.2% to 99.97%, p95 latency dropped to 320 ms (-53%), P1 incidents fell from 27 to four per month, and chargebacks decreased 18%. I ensured Black Friday processed 3.8 million transactions per day with no degradation, lifted post-event NPS from 61 to 79, and cut BACEN complaints by 42%. I shipped phase two 45 days later with zero critical incidents and created a weekly Postmortem Council to keep the learning alive. The scope-cut trade-off generated long-term dividends: over the next 18 months, the platform maintained 99.96% average availability (vs. 99.1% for competing platforms), reduced mean time to recovery (MTTR) from 47 to 8 minutes, and enabled scaling from 8K to 24K TPS without core rewrite. The resilience framework I created (circuit breaker + 96 alerts + game days) was adopted by 12 squads and prevented 8 critical incidents by detecting degradation before customer impact. The CFO calculated we avoided R$67M in potential losses (chargebacks + fines + churn) over 2 years.",
      "l": "The main lesson from this case transformed my understanding of ownership: sometimes it means saying no when data shows customers would pay the price — leading with evidence and permanent mechanisms preserves long-term trust.\n\nI learned that ownership sometimes means saying no when the data shows the customer would pay the price. I proved that leading with evidence, bringing the customer into the room, and leaving permanent resilience mechanisms preserves trust. Three principles guide my approach since then: (1) Long-term robustness > short-term features: customers prefer five stable functions over 14 unstable ones, (2) Resilience mechanisms are investment, not cost: circuit breaker + game days + Postmortem Council generated 28:1 ROI by preventing incidents, (3) Transparent trade-off with data builds trust: by showing risk heatmap to CEO and merchants, I turned resistance into advocacy. This model was replicated in PIX Phase 2 (cut 6 of 11 features, delivered 3 days before BACEN deadline with 99.98% availability) and Open Finance (deferred 4 integrations, zeroed P1 incidents in BCB approval). I transformed this checklist into my standard: never commit deadline without load test, risk model, and objective gates. Taking the hard short-term trade-off earned me reputation for \"delivery with quality\" and was cited by CEO as example of \"ownership that protects the customer\"."
    },
    "fups": [
      {
        "q": "Como calculou o risco financeiro de R$ 24M ao manter o escopo completo?",
        "a": "Eu modelei perda por SLA quebrado (R$ 8,5M), chargebacks adicionais (R$ 11M) e multa potencial do BACEN (R$ 4,5M). Eu usei histórico de 18 incidentes e curvas de churn para projetar o impacto e apresentei ao CFO e ao CEO antes de votar pelo gate.",
        "q_en": "How did you calculate the R$24M financial risk for keeping the full scope?",
        "a_en": "I modeled SLA penalties (R$8.5M), incremental chargebacks (R$11M), and a potential BACEN fine (R$4.5M), using 18 past incidents and churn curves to project the exposure and presenting it to the CFO and CEO before the gate vote."
      },
      {
        "q": "Quais experimentos de carga sustentaram sua decisão?",
        "a": "Eu rodei 42 cenários no Locust simulando picos de 6K a 12K TPS com mix real de transações. Eu identifiquei gargalo em pooling e falha de timeout no antifraude, documentei em laudos anexados ao comitê e usei para priorizar correções.",
        "q_en": "Which load experiments supported your call?",
        "a_en": "I executed 42 Locust scenarios from 6K to 12K TPS with real transaction mixes, identifying a pooling bottleneck and antifraud timeout, documenting them for the executive committee and prioritizing fixes accordingly."
      },
      {
        "q": "Como alinhou merchants estratégicos à decisão de adiar features?",
        "a": "Eu mapeei os 20 maiores merchants por volume, discuti o plano em reuniões individuais e configurei feature flags para liberar funcionalidades críticas somente quando estáveis. Eu ofereci playbooks de contingência e canais diretos com SRE durante o pico.",
        "q_en": "How did you align strategic merchants around delaying features?",
        "a_en": "I mapped the top 20 merchants by volume, held one-on-one sessions, configured feature flags to release critical capabilities only when stable, and provided contingency playbooks with direct SRE channels during the peak."
      },
      {
        "q": "Que métricas compuseram o heatmap que convenceu o comitê executivo?",
        "a": "Eu usei nove métricas: CPU, memória, latência p95, erros 5xx, chargeback ratio, fraude bloqueada, SLA de disputa, backlog P1 e NPS previsto. Cada métrica tinha threshold com risco financeiro associado.",
        "q_en": "Which metrics were in the heatmap that convinced the executive committee?",
        "a_en": "I used nine metrics: CPU, memory, p95 latency, 5xx errors, chargeback ratio, fraud blocked, dispute SLA, P1 backlog, and forecasted NPS, each with thresholds and linked financial risk."
      },
      {
        "q": "Como monitorou e reagiu durante a Black Friday?",
        "a": "Eu montei war room 24/7, três dashboards em tempo real, runbooks com RTO de 15 minutos e canal direto com Marketing e NOC. Qualquer métrica fora do envelope disparava playbook de contingência com freeze automático de features secundárias.",
        "q_en": "How did you monitor and react during Black Friday?",
        "a_en": "I ran a 24/7 war room with three real-time dashboards, playbooks with a 15-minute RTO, and a direct channel with Marketing and the NOC. Any metric outside the envelope triggered contingency playbooks and automatic freeze of secondary features."
      },
      {
        "q": "De que forma mediu e comprovou o ganho de NPS e redução de reclamações?",
        "a": "Eu comparei pesquisas NPS pré e pós-Black Friday (amostra de 8 mil clientes) e correlacionei com dados de chargeback e tickets. Eu monitorei portal do BACEN e Reclame Aqui e validei a queda de 42% com o jurídico.",
        "q_en": "How did you measure the NPS gain and complaint reduction?",
        "a_en": "I compared pre- and post-Black Friday NPS surveys (8K customers), correlated them with chargeback and ticket data, monitored BACEN and Reclame Aqui complaints, and confirmed the 42% drop with legal."
      },
      {
        "q": "Como manteve o squad motivado depois de reduzir o escopo?",
        "a": "Eu redefini OKRs com foco em resiliência, criei reconhecimento semanal e reservei 15% da sprint para melhorias técnicas escolhidas pelo time. Eu comuniquei a vitória no dia seguinte à Black Friday com métricas claras de impacto.",
        "q_en": "How did you keep the squad motivated after the scope cut?",
        "a_en": "I reframed OKRs around resilience, set up a weekly recognition loop, reserved 15% of each sprint for engineering improvements chosen by the team, and communicated the Black Friday win the very next day with clear metrics."
      },
      {
        "q": "Quais ajustes liberaram a fase dois em 45 dias?",
        "a": "Eu implementei connection pooling dinâmico, refatorei antifraude para streaming, elevei cobertura de testes de carga para 85% do mapa de fluxos e adicionei canary release com rollback automático. Todos os gates ficaram verdes na segunda rodada.",
        "q_en": "What adjustments enabled phase two in 45 days?",
        "a_en": "I delivered dynamic connection pooling, refactored antifraud to streaming, increased load-test coverage to 85% of the flow map, and added canary releases with automatic rollback. All gates turned green on the second run."
      },
      {
        "q": "Como funciona o Postmortem Council que você criou?",
        "a": "Eu conduzo um rito semanal com SRE, produto e risco. Eu reviso incidentes, métricas de resiliência e defino actions com responsáveis e prazos. As lições entram em repositório público e viram critérios obrigatórios para novos lançamentos.",
        "q_en": "How does the Postmortem Council you created operate?",
        "a_en": "I run a weekly ritual with SRE, product, and risk reviewing incidents, resilience metrics, and assigning actions with owners and due dates. Lessons go to a public repository and become mandatory criteria for future launches."
      },
      {
        "q": "Se conduzisse esse lançamento novamente, o que faria diferente?",
        "a": "Eu iniciaria modelagem de risco e testes de carga já na fase de ideação. No projeto original esses artefatos chegaram apenas na pré-release; antecipando, eu reduziria a necessidade de cortar escopo na reta final.",
        "q_en": "If you led this launch again, what would you change?",
        "a_en": "I would start risk modeling and load testing during ideation. In the original project those assets appeared only right before release; anticipating them would reduce late scope cuts."
      }
    ],
    "__file": "src\\data\\ownership\\ownership_case6.js",
    "lp_id": "ownership",
    "__load_warnings": []
  },
  "mutated": {
    "id": "long-term-tradeoff",
    "title": "Assumi Trade-off: Menos Escopo Agora por Maior Robustez",
    "title_pt": "Assumi Trade-off: Menos Escopo Agora por Maior Robustez",
    "title_en": "Took the Trade-off: Less Scope Now for Greater Robustness",
    "company": "Bradesco Next",
    "period": "07/2017-12/2017",
    "isTopCase": false,
    "isGoodCase": false,
    "pt": {
      "s": "\"Vamos lançar todas as 14 features na Black Friday — marketing já prometeu.\" A frase do CPO em reunião executiva ignorava os dados brutais: 680 ms de latência (+45%), 27 incidentes P1 no backlog, chargebacks crescendo 19%/mês, e alerta do NOC de que 8K TPS derrubariam o core legado a 92% CPU, comprometendo 3,5 milhões de transações/dia para 1,2 milhão de clientes. Stakes: lançar tudo sem hardening = R$ 24M em perdas potenciais (multas + chargebacks + churn); cortar escopo = enfrentar CPO + marketing + promessas públicas. Dilema de ownership: proteger 1,2 milhão de clientes com decisão impopular ou ceder à pressão e arriscar colapso na Black Friday.\n\nEu liderava a integração de pagamentos no banco digital Next quando o squad planejava lançar 14 features em uma única release para a Black Friday. Eu enxergava latência média em 680 ms (+45%), backlog com 27 incidentes P1 e chargebacks crescendo 19% ao mês. Eu recebi alerta do NOC de que sob pico de 8 mil transações por segundo o core legado bateria 92% de CPU e poderia derrubar 3,5 milhões de transações por dia. O CPO insistia em manter o roadmap completo porque o marketing já prometera as novidades para 1,2 milhão de clientes.",
      "t": "O desafio crítico que enfrentei foi assumir ownership total do core — além do meu escopo formal de integrações — e tomar decisão impopular de cortar 9 de 14 features para proteger 1,2 milhão de clientes de colapso iminente na Black Friday.\n\nMeu escopo formal cobria integrações com parceiros, mas eu assumi ownership total do core. Eu estabeleci metas: manter disponibilidade acima de 99,9%, reduzir chargebacks em pelo menos 15% e liberar a release em duas ondas somente quando os controles críticos passassem em testes de carga. Eu avisei o CEO que cortaria a primeira onda para cinco features essenciais e entregaria o restante quando os gates estivesse verdes.",
      "a": "Minha abordagem foi construir modelo de risco baseado em dados, formar tiger team multifuncional em 48h e negociar trade-off transparente com CEO/merchants usando evidências concretas de degradação sob carga.\n\nEu formei uma tiger team com SRE, risco e produto em 48 horas. (1) Eu modelei cenários financeiros mostrando perda potencial de R$ 24M em multas, chargebacks e churn se lançássemos tudo sem reforço. (2) Eu orquestrei testes de carga com Locust até 12 mil TPS e provei que aos 7.600 TPS o core travava por limite de pooling. (3) Eu reescrevi o plano em duas fases: fase um com cinco features críticas (PIX recorrente, limites dinâmicos, antifraude adaptativo, SLA de disputa, painel de cashback) e fase dois pós-hardening. (4) Eu implantei mecanismos: circuit breaker, 96 alertas Prometheus, feature flags por segmento e game days duas vezes por semana. (5) Eu negociei com marketing e compliance uma campanha trust-first baseada nas cinco features e um roadmap público ancorado em marcos de estabilidade. (6) Eu enfrentei resistência do CPO no comitê executivo mostrando heatmap com nove métricas críticas (CPU, latência p95, chargeback ratio, SLA antifraude) e votei pelo gate até que os riscos ficassem aceitáveis; o CEO apoiou ao ver o modelo risco versus NPS. (7) Eu sentei no call center e reuni os cinco maiores merchants (iFood, Magazine Luiza, Rappi, Uber, B2W) para explicar o plano, ajustar feature flags e garantir SLA dedicado durante o pico.",
      "r": "O impacto mensurável para 1,2 milhão de clientes — resultado direto do trade-off de cortar 9 features para garantir robustez — transformou decisão impopular em dividendos de longo prazo.\n\nEu estabilizei o core em 28 dias mantendo apenas cinco features: disponibilidade subiu de 99,2% para 99,97%, latência p95 caiu para 320 ms (-53%), incidentes P1 reduziram de 27 para quatro por mês e chargebacks baixaram 18%. Eu garanti que a Black Friday processasse 3,8 milhões de transações por dia sem degradação, elevei o NPS pós-evento de 61 para 79 e reduzi reclamações no BACEN em 42%. Eu liberei a fase dois 45 dias depois com zero incidentes críticos e instituí um Postmortem Council semanal para manter o aprendizado vivo. O trade-off de cortar escopo gerou dividendos de longo prazo: nos 18 meses seguintes, a plataforma manteve disponibilidade média de 99,96% (vs. 99,1% em plataformas concorrentes), reduziu tempo médio de recuperação (MTTR) de 47 para 8 minutos e permitiu escalar de 8K para 24K TPS sem reescrever core. O framework de resiliência que criei (circuit breaker + 96 alertas + game days) foi adotado por 12 squads e preveniu 8 incidentes críticos ao detectar degradação antes de impactar clientes. O CFO calculou que evitamos R$ 67M em perdas potenciais (chargebacks + multas + churn) ao longo de 2 anos.",
      "l": "A lição principal desse caso transformou minha compreensão de ownership: às vezes significa dizer não quando dados mostram que clientes pagariam o preço — liderar com evidências e mecanismos permanentes preserva confiança de longo prazo muito além de features incrementais.\n\nEu aprendi que ownership inclui dizer não quando os dados mostram que o cliente pagaria a conta. Eu comprovei que liderar com evidências, trazer o cliente para a mesa e deixar mecanismos permanentes preserva confiança. Três princípios guiam meu approach desde então: (1) Long-term robustez > short-term features: clientes preferem cinco funcionalidades estáveis a 14 instáveis, (2) Mecanismos de resiliência são investimento, não custo: circuit breaker + game days + Postmortem Council geraram ROI de 28:1 ao prevenir incidentes, (3) Trade-off transparente com dados constrói confiança: ao mostrar heatmap de risco ao CEO e merchants, transformei resistência em advocacy. Esse modelo foi replicado em PIX Phase 2 (cortei 6 de 11 features, entreguei 3 dias antes do deadline BACEN com 99,98% disponibilidade) e Open Finance (adiamos 4 integrações, zeramos incidentes P1 em homologação BCB). Eu transformei esse checklist no meu padrão: nunca commito deadline sem load test, risk model e gates objetivos. Assumir trade-off difícil no curto prazo me rendeu reputação de \"entrega com qualidade\" e foi citado pelo CEO como exemplo de \"ownership que protege o cliente\"."
    },
    "en": {
      "s": "\"Let's ship all 14 features for Black Friday — marketing already promised.\" The CPO's phrase in executive meeting ignored brutal data: 680 ms latency (+45%), 27 P1 incidents in backlog, chargebacks climbing 19%/month, and NOC warning that 8K TPS would crash legacy core at 92% CPU, compromising 3.5M transactions/day for 1.2M customers. Stakes: ship everything without hardening = R$24M in potential losses (penalties + chargebacks + churn); cut scope = face CPO + marketing + public promises. Ownership dilemma: protect 1.2M customers with unpopular decision or yield to pressure and risk Black Friday collapse.\n\nI was leading payments integration at Next digital bank when the squad planned to ship 14 features in a single release for Black Friday. I saw average latency at 680 ms (+45%), a backlog of 27 P1 incidents, and chargebacks climbing 19% month over month. The NOC warned me that under the 8K TPS peak the legacy core would hit 92% CPU and could knock out 3.5 million transactions per day. The CPO insisted on shipping the full roadmap because marketing had promised it to 1.2 million customers.",
      "t": "The critical challenge I faced was taking total ownership of the core — beyond my formal integrations scope — and making the unpopular decision to cut 9 of 14 features to protect 1.2M customers from imminent Black Friday collapse.\n\nMy formal remit covered partner integrations, but I took full ownership of the core. I set the goals: keep availability above 99.9%, cut chargebacks by at least 15%, and release in two waves only after critical controls passed load testing. I told the CEO I would trim the first wave to five essential features and deliver the rest once the gates were green.",
      "a": "My approach was to build data-driven risk model, form cross-functional tiger team in 48h, and negotiate transparent trade-off with CEO/merchants using concrete evidence of degradation under load.\n\nI formed a tiger team with SRE, risk, and product in 48 hours. (1) I built financial scenarios that showed a potential R$24M loss in penalties, chargebacks, and churn if we launched everything without hardening. (2) I orchestrated Locust load tests up to 12K TPS and proved the core stalled at 7,600 TPS because of pooling limits. (3) I rewrote the roadmap into two phases: phase one with five critical features (recurring PIX, dynamic limits, adaptive antifraud, dispute SLA automation, cashback dashboard) and phase two after hardening. (4) I implemented mechanisms: circuit breaker, 96 Prometheus alerts, segment-based feature flags, and twice-weekly game days. (5) I negotiated a trust-first campaign with marketing and compliance anchored on the five features and a public roadmap tied to stability milestones. (6) I faced the CPO pushback in the executive committee by presenting a heatmap with nine critical metrics (CPU, p95 latency, chargeback ratio, antifraud SLA), voting to hold the gate until the risk dropped; the CEO backed the decision after seeing the risk-versus-NPS model. (7) I took call-center shifts and met top merchants (iFood, Magazine Luiza, Rappi, Uber, B2W) to explain the plan, tune feature flags, and guarantee dedicated SLAs during the peak.",
      "r": "The measurable impact for 1.2M customers — direct result of the trade-off to cut 9 features for robustness — transformed unpopular decision into long-term dividends.\n\nBy holding the scope to five features I stabilized the core in 28 days: availability rose from 99.2% to 99.97%, p95 latency dropped to 320 ms (-53%), P1 incidents fell from 27 to four per month, and chargebacks decreased 18%. I ensured Black Friday processed 3.8 million transactions per day with no degradation, lifted post-event NPS from 61 to 79, and cut BACEN complaints by 42%. I shipped phase two 45 days later with zero critical incidents and created a weekly Postmortem Council to keep the learning alive. The scope-cut trade-off generated long-term dividends: over the next 18 months, the platform maintained 99.96% average availability (vs. 99.1% for competing platforms), reduced mean time to recovery (MTTR) from 47 to 8 minutes, and enabled scaling from 8K to 24K TPS without core rewrite. The resilience framework I created (circuit breaker + 96 alerts + game days) was adopted by 12 squads and prevented 8 critical incidents by detecting degradation before customer impact. The CFO calculated we avoided R$67M in potential losses (chargebacks + fines + churn) over 2 years.",
      "l": "The main lesson from this case transformed my understanding of ownership: sometimes it means saying no when data shows customers would pay the price — leading with evidence and permanent mechanisms preserves long-term trust.\n\nI learned that ownership sometimes means saying no when the data shows the customer would pay the price. I proved that leading with evidence, bringing the customer into the room, and leaving permanent resilience mechanisms preserves trust. Three principles guide my approach since then: (1) Long-term robustness > short-term features: customers prefer five stable functions over 14 unstable ones, (2) Resilience mechanisms are investment, not cost: circuit breaker + game days + Postmortem Council generated 28:1 ROI by preventing incidents, (3) Transparent trade-off with data builds trust: by showing risk heatmap to CEO and merchants, I turned resistance into advocacy. This model was replicated in PIX Phase 2 (cut 6 of 11 features, delivered 3 days before BACEN deadline with 99.98% availability) and Open Finance (deferred 4 integrations, zeroed P1 incidents in BCB approval). I transformed this checklist into my standard: never commit deadline without load test, risk model, and objective gates. Taking the hard short-term trade-off earned me reputation for \"delivery with quality\" and was cited by CEO as example of \"ownership that protects the customer\"."
    },
    "fups": [
      {
        "q": "Como calculou o risco financeiro de R$ 24M ao manter o escopo completo?",
        "a": "Eu modelei perda por SLA quebrado (R$ 8,5M), chargebacks adicionais (R$ 11M) e multa potencial do BACEN (R$ 4,5M). Eu usei histórico de 18 incidentes e curvas de churn para projetar o impacto e apresentei ao CFO e ao CEO antes de votar pelo gate.",
        "q_en": "How did you calculate the R$24M financial risk for keeping the full scope?",
        "a_en": "I modeled SLA penalties (R$8.5M), incremental chargebacks (R$11M), and a potential BACEN fine (R$4.5M), using 18 past incidents and churn curves to project the exposure and presenting it to the CFO and CEO before the gate vote."
      },
      {
        "q": "Quais experimentos de carga sustentaram sua decisão?",
        "a": "Eu rodei 42 cenários no Locust simulando picos de 6K a 12K TPS com mix real de transações. Eu identifiquei gargalo em pooling e falha de timeout no antifraude, documentei em laudos anexados ao comitê e usei para priorizar correções.",
        "q_en": "Which load experiments supported your call?",
        "a_en": "I executed 42 Locust scenarios from 6K to 12K TPS with real transaction mixes, identifying a pooling bottleneck and antifraud timeout, documenting them for the executive committee and prioritizing fixes accordingly."
      },
      {
        "q": "Como alinhou merchants estratégicos à decisão de adiar features?",
        "a": "Eu mapeei os 20 maiores merchants por volume, discuti o plano em reuniões individuais e configurei feature flags para liberar funcionalidades críticas somente quando estáveis. Eu ofereci playbooks de contingência e canais diretos com SRE durante o pico.",
        "q_en": "How did you align strategic merchants around delaying features?",
        "a_en": "I mapped the top 20 merchants by volume, held one-on-one sessions, configured feature flags to release critical capabilities only when stable, and provided contingency playbooks with direct SRE channels during the peak."
      },
      {
        "q": "Que métricas compuseram o heatmap que convenceu o comitê executivo?",
        "a": "Eu usei nove métricas: CPU, memória, latência p95, erros 5xx, chargeback ratio, fraude bloqueada, SLA de disputa, backlog P1 e NPS previsto. Cada métrica tinha threshold com risco financeiro associado.",
        "q_en": "Which metrics were in the heatmap that convinced the executive committee?",
        "a_en": "I used nine metrics: CPU, memory, p95 latency, 5xx errors, chargeback ratio, fraud blocked, dispute SLA, P1 backlog, and forecasted NPS, each with thresholds and linked financial risk."
      },
      {
        "q": "Como monitorou e reagiu durante a Black Friday?",
        "a": "Eu montei war room 24/7, três dashboards em tempo real, runbooks com RTO de 15 minutos e canal direto com Marketing e NOC. Qualquer métrica fora do envelope disparava playbook de contingência com freeze automático de features secundárias.",
        "q_en": "How did you monitor and react during Black Friday?",
        "a_en": "I ran a 24/7 war room with three real-time dashboards, playbooks with a 15-minute RTO, and a direct channel with Marketing and the NOC. Any metric outside the envelope triggered contingency playbooks and automatic freeze of secondary features."
      },
      {
        "q": "De que forma mediu e comprovou o ganho de NPS e redução de reclamações?",
        "a": "Eu comparei pesquisas NPS pré e pós-Black Friday (amostra de 8 mil clientes) e correlacionei com dados de chargeback e tickets. Eu monitorei portal do BACEN e Reclame Aqui e validei a queda de 42% com o jurídico.",
        "q_en": "How did you measure the NPS gain and complaint reduction?",
        "a_en": "I compared pre- and post-Black Friday NPS surveys (8K customers), correlated them with chargeback and ticket data, monitored BACEN and Reclame Aqui complaints, and confirmed the 42% drop with legal."
      },
      {
        "q": "Como manteve o squad motivado depois de reduzir o escopo?",
        "a": "Eu redefini OKRs com foco em resiliência, criei reconhecimento semanal e reservei 15% da sprint para melhorias técnicas escolhidas pelo time. Eu comuniquei a vitória no dia seguinte à Black Friday com métricas claras de impacto.",
        "q_en": "How did you keep the squad motivated after the scope cut?",
        "a_en": "I reframed OKRs around resilience, set up a weekly recognition loop, reserved 15% of each sprint for engineering improvements chosen by the team, and communicated the Black Friday win the very next day with clear metrics."
      },
      {
        "q": "Quais ajustes liberaram a fase dois em 45 dias?",
        "a": "Eu implementei connection pooling dinâmico, refatorei antifraude para streaming, elevei cobertura de testes de carga para 85% do mapa de fluxos e adicionei canary release com rollback automático. Todos os gates ficaram verdes na segunda rodada.",
        "q_en": "What adjustments enabled phase two in 45 days?",
        "a_en": "I delivered dynamic connection pooling, refactored antifraud to streaming, increased load-test coverage to 85% of the flow map, and added canary releases with automatic rollback. All gates turned green on the second run."
      },
      {
        "q": "Como funciona o Postmortem Council que você criou?",
        "a": "Eu conduzo um rito semanal com SRE, produto e risco. Eu reviso incidentes, métricas de resiliência e defino actions com responsáveis e prazos. As lições entram em repositório público e viram critérios obrigatórios para novos lançamentos.",
        "q_en": "How does the Postmortem Council you created operate?",
        "a_en": "I run a weekly ritual with SRE, product, and risk reviewing incidents, resilience metrics, and assigning actions with owners and due dates. Lessons go to a public repository and become mandatory criteria for future launches."
      },
      {
        "q": "Se conduzisse esse lançamento novamente, o que faria diferente?",
        "a": "Eu iniciaria modelagem de risco e testes de carga já na fase de ideação. No projeto original esses artefatos chegaram apenas na pré-release; antecipando, eu reduziria a necessidade de cortar escopo na reta final.",
        "q_en": "If you led this launch again, what would you change?",
        "a_en": "I would start risk modeling and load testing during ideation. In the original project those assets appeared only right before release; anticipating them would reduce late scope cuts."
      }
    ],
    "__file": "src\\data\\ownership\\ownership_case6.js",
    "lp_id": "ownership",
    "__load_warnings": [],
    "__scorecard": {
      "score": 96,
      "status": "Ready",
      "positives": [
        "Métricas robustas (56)",
        "Ratio EU:NÓS saudável (14.3:1)"
      ],
      "warnings": [],
      "dealbreakers": [],
      "suggestions": [],
      "lint": {
        "ok": true,
        "issues": [],
        "warnings": []
      },
      "heur": {
        "score": 96,
        "status": "Ready",
        "dealbreakers": [],
        "warnings": [],
        "positives": [
          "Métricas robustas (56)",
          "Ratio EU:NÓS saudável (14.3:1)"
        ],
        "breakdown": {
          "narrative": 17,
          "metrics": 20,
          "lpContent": 16,
          "amazonAspects": 15,
          "contribution": 10,
          "structure": 10
        },
        "details": {
          "metrics": {
            "count": 56,
            "hasFinancial": true,
            "hasCustomer": true,
            "hasOperational": true
          },
          "contribution": {
            "ratio": 14.333333333333334,
            "eu": 43,
            "nos": 3
          },
          "amazonAspects": {
            "customerSignals": 17,
            "mechanismSignals": 5,
            "conflictSignals": 15
          },
          "lpContent": {
            "strongCount": 8,
            "mediumCount": 0
          }
        }
      }
    }
  }
}